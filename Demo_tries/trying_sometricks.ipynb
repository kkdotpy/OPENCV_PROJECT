{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "072171b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from threading import Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1a2186",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6867fa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class VideoStream:\n",
    "    def __init__(self, src):\n",
    "        self.stream = cv.VideoCapture(src)\n",
    "        self.stopped = False\n",
    "        self.frame = None\n",
    "\n",
    "    def start(self):\n",
    "        Thread(target=self.update, args=(), daemon=True).start()\n",
    "        return self  # So you can do .start().read()\n",
    "\n",
    "    def update(self):\n",
    "        while not self.stopped:\n",
    "            if self.stream.isOpened():\n",
    "                ret, frame = self.stream.read()\n",
    "                if ret:\n",
    "                    self.frame = frame\n",
    "\n",
    "    def read(self):\n",
    "        return self.frame\n",
    "\n",
    "    def stop(self):\n",
    "        self.stopped = True\n",
    "        self.stream.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85b27b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capturing video frame from both phone cameras \n",
    "\n",
    "cap1 = VideoStream('http://192.168.0.177:4747/video').start()  # Left view\n",
    "cap2 = VideoStream('http://192.168.0.114:4747/video').start() # Right view\n",
    "\n",
    "#Process frames function => INcludes resizing, converting to grayscale, and reducing noise by blurring\n",
    "\n",
    "def process_frames(frame):\n",
    "    frame = cv.resize(frame, (640, 480))  # Resize to a standard size\n",
    "    gray_frame = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)  # Convert to grayscale\n",
    "    return gray_frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e633e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\khare\\Anaconda3\\lib\\threading.py\", line 980, in _bootstrap_inner\n",
      "Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\khare\\Anaconda3\\lib\\threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\khare\\Anaconda3\\lib\\threading.py\", line 917, in run\n",
      "    self.run()\n",
      "  File \"c:\\Users\\khare\\Anaconda3\\lib\\threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\khare\\AppData\\Local\\Temp\\ipykernel_30148\\3743077464.py\", line 14, in update\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\khare\\AppData\\Local\\Temp\\ipykernel_30148\\3743077464.py\", line 14, in update\n",
      "cv2.error: Unknown C++ exception from OpenCV code\n",
      "cv2.error: Unknown C++ exception from OpenCV code\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Background subtractors\n",
    "bg_sub1 = cv.createBackgroundSubtractorMOG2(history=100, varThreshold=50, detectShadows=False)\n",
    "bg_sub2 = cv.createBackgroundSubtractorMOG2(history=100, varThreshold=50, detectShadows=False)\n",
    "\n",
    "frame_count = 0  # for warming up background model\n",
    "\n",
    "while True:\n",
    "    frame1 = cap1.read()\n",
    "    frame2 = cap2.read()\n",
    "\n",
    "    if frame1 is None or frame2 is None:\n",
    "        print(\"Waiting for frames...\")\n",
    "        continue\n",
    "\n",
    "    frame1 = process_frames(frame1)\n",
    "    frame2 = process_frames(frame2)\n",
    "\n",
    "    frame_count += 1\n",
    "    if frame_count < 30:  # allow background subtractor to warm up\n",
    "        bg_sub1.apply(frame1)\n",
    "        bg_sub2.apply(frame2)\n",
    "        continue\n",
    "\n",
    "    # Get foreground masks\n",
    "    fg_mask1 = bg_sub1.apply(frame1)\n",
    "    fg_mask2 = bg_sub2.apply(frame2)\n",
    "\n",
    "    # Clean up noise in masks\n",
    "    fg_mask1 = cv.medianBlur(fg_mask1, 5)\n",
    "    fg_mask2 = cv.medianBlur(fg_mask2, 5)\n",
    "\n",
    "    # Apply mask to get foreground objects\n",
    "    fg1 = cv.bitwise_and(frame1, frame1, mask=fg_mask1)\n",
    "    fg2 = cv.bitwise_and(frame2, frame2, mask=fg_mask2)\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray1 = cv.cvtColor(fg1, cv.COLOR_BGR2GRAY) if len(fg1.shape) == 3 else fg1\n",
    "    gray2 = cv.cvtColor(fg2, cv.COLOR_BGR2GRAY) if len(fg2.shape) == 3 else fg2\n",
    "\n",
    "    # Check for motion activity\n",
    "    active1 = np.count_nonzero(fg_mask1) > 1000\n",
    "    active2 = np.count_nonzero(fg_mask2) > 1000\n",
    "\n",
    "    display = frame2.copy()\n",
    "\n",
    "    if active1 and active2:\n",
    "        # Compute absolute difference and threshold\n",
    "        diff = cv.absdiff(gray1, gray2)\n",
    "        _, thresh = cv.threshold(diff, 30, 255, cv.THRESH_BINARY)\n",
    "\n",
    "        # Find and draw contours\n",
    "        contours, _ = cv.findContours(thresh, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "        cv.drawContours(display, contours, -1, (0, 0, 255), 2)\n",
    "\n",
    "        # Similarity scoring\n",
    "        nonzero = np.count_nonzero(thresh)\n",
    "        total = thresh.shape[0] * thresh.shape[1]\n",
    "        score = 100 - (nonzero / total * 100)\n",
    "        cv.putText(display, f\"Similarity: {score:.2f}%\", (10, 30),\n",
    "                   cv.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "        if score < 80:\n",
    "            cv.putText(display, \"Movement Not Synchronized!\", (10, 460),\n",
    "                       cv.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "    else:\n",
    "        # No significant motion in one or both\n",
    "        cv.putText(display, \"No significant motion in one or both feeds!\", (10, 30),\n",
    "                   cv.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "\n",
    "    # Show results\n",
    "    cv.imshow(\"Left View\", frame1)\n",
    "    cv.imshow(\"Right View\", frame2)\n",
    "    cv.imshow(\"Difference Highlighted\", display)\n",
    "    cv.imshow(\"Threshold Map\", thresh if active1 and active2 else np.zeros_like(gray1))\n",
    "\n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "cap1.stop()\n",
    "cap2.stop()\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "800b1cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press 'q' to quit. Press 'r' to reset canvases.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-15:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\khare\\Anaconda3\\lib\\threading.py\", line 980, in _bootstrap_inner\n",
      "Exception in thread Thread-16:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\khare\\Anaconda3\\lib\\threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\khare\\Anaconda3\\lib\\threading.py\", line 917, in run\n",
      "    self.run()\n",
      "  File \"c:\\Users\\khare\\Anaconda3\\lib\\threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\khare\\AppData\\Local\\Temp\\ipykernel_48148\\596969375.py\", line 27, in update\n",
      "cv2.error: Unknown C++ exception from OpenCV code\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\khare\\AppData\\Local\\Temp\\ipykernel_48148\\596969375.py\", line 27, in update\n",
      "cv2.error: Unknown C++ exception from OpenCV code\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from threading import Thread\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "# === Fingertip Color Range in HSV (Adjust as needed) ===\n",
    "lower_color = np.array([0, 150, 100])     # Red hue lower bound\n",
    "upper_color = np.array([10, 255, 255])    # Red hue upper bound\n",
    "\n",
    "# === Canvas Size ===\n",
    "WIDTH, HEIGHT = 640, 480\n",
    "\n",
    "# === VideoStream Class for Better Performance ===\n",
    "class VideoStream:\n",
    "    def __init__(self, src):\n",
    "        self.stream = cv.VideoCapture(src)\n",
    "        self.stopped = False\n",
    "        self.frame = None\n",
    "\n",
    "    def start(self):\n",
    "        Thread(target=self.update, args=(), daemon=True).start()\n",
    "        return self\n",
    "\n",
    "    def update(self):\n",
    "        while not self.stopped:\n",
    "            if self.stream.isOpened():\n",
    "                ret, frame = self.stream.read()\n",
    "                if ret:\n",
    "                    self.frame = frame\n",
    "\n",
    "    def read(self):\n",
    "        return self.frame\n",
    "\n",
    "    def stop(self):\n",
    "        self.stopped = True\n",
    "        self.stream.release()\n",
    "\n",
    "# === Initialize Streams ===\n",
    "vs1 = VideoStream('http://192.168.0.177:4747/video').start()  # Back view\n",
    "vs2 = VideoStream('http://192.168.0.114:4747/video').start() # Front view\n",
    "canvas1 = np.zeros((HEIGHT, WIDTH, 3), dtype=np.uint8)\n",
    "canvas2 = np.zeros((HEIGHT, WIDTH, 3), dtype=np.uint8)\n",
    "\n",
    "last_point1, last_point2 = None, None\n",
    "\n",
    "def detect_finger(frame):\n",
    "    if frame is None:\n",
    "        return None\n",
    "    frame = cv.flip(frame, 1)\n",
    "    hsv = cv.cvtColor(frame, cv.COLOR_BGR2HSV)\n",
    "    mask = cv.inRange(hsv, lower_color, upper_color)\n",
    "    contours, _ = cv.findContours(mask, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if contours:\n",
    "        largest = max(contours, key=cv.contourArea)\n",
    "        if cv.contourArea(largest) > 300:\n",
    "            M = cv.moments(largest)\n",
    "            if M['m00'] != 0:\n",
    "                cx = int(M['m10'] / M['m00'])\n",
    "                cy = int(M['m01'] / M['m00'])\n",
    "                return (cx, cy)\n",
    "    return None\n",
    "\n",
    "def update_canvas(canvas, point, last_point):\n",
    "    if point and last_point:\n",
    "        cv.line(canvas, last_point, point, (255, 255, 255), 4)\n",
    "\n",
    "def compare_images(img1, img2):\n",
    "    gray1 = cv.cvtColor(img1, cv.COLOR_BGR2GRAY)\n",
    "    gray2 = cv.cvtColor(img2, cv.COLOR_BGR2GRAY)\n",
    "    gray1 = cv.resize(gray1, (256, 256))\n",
    "    gray2 = cv.resize(gray2, (256, 256))\n",
    "    score, diff = ssim(gray1, gray2, full=True)\n",
    "    diff = (diff * 255).astype(\"uint8\")\n",
    "    return score, cv.cvtColor(diff, cv.COLOR_GRAY2BGR)\n",
    "\n",
    "print(\"Press 'q' to quit. Press 'r' to reset canvases.\")\n",
    "\n",
    "while True:\n",
    "    frame1 = vs1.read()\n",
    "    frame2 = vs2.read()\n",
    "\n",
    "    if frame1 is None or frame2 is None:\n",
    "        continue\n",
    "\n",
    "    point1 = detect_finger(frame1)\n",
    "    point2 = detect_finger(frame2)\n",
    "\n",
    "    update_canvas(canvas1, point1, last_point1)\n",
    "    update_canvas(canvas2, point2, last_point2)\n",
    "\n",
    "    last_point1 = point1\n",
    "    last_point2 = point2\n",
    "\n",
    "    score, diff_canvas = compare_images(canvas1, canvas2)\n",
    "    cv.putText(diff_canvas, f\"Score: {score:.2f}\", (10, 30),\n",
    "               cv.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    cv.imshow(\"Back Drawing\", canvas1)\n",
    "    cv.imshow(\"Front Drawing\", canvas2)\n",
    "    cv.imshow(\"Difference\", diff_canvas)\n",
    "\n",
    "    key = cv.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('r'):\n",
    "        canvas1[:] = 0\n",
    "        canvas2[:] = 0\n",
    "        last_point1 = last_point2 = None\n",
    "\n",
    "vs1.stop()\n",
    "vs2.stop()\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc2e684",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-10:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\khare\\Anaconda3\\lib\\threading.py\", line 980, in _bootstrap_inner\n",
      "Exception in thread Thread-11:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\khare\\Anaconda3\\lib\\threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\khare\\Anaconda3\\lib\\threading.py\", line 917, in run\n",
      "    self.run()\n",
      "  File \"c:\\Users\\khare\\Anaconda3\\lib\\threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\khare\\AppData\\Local\\Temp\\ipykernel_49316\\4231596643.py\", line 25, in update\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\khare\\AppData\\Local\\Temp\\ipykernel_49316\\4231596643.py\", line 25, in update\n",
      "cv2.error: Unknown C++ exception from OpenCV code\n",
      "cv2.error: Unknown C++ exception from OpenCV code\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from threading import Thread\n",
    "import mediapipe as mp\n",
    "\n",
    "# === Canvas Settings ===\n",
    "WIDTH, HEIGHT = 640, 480\n",
    "DRAW_COLOR = (0, 0, 0)  # Black drawing on white background\n",
    "LINE_THICKNESS = 8\n",
    "\n",
    "# === VideoStream Class ===\n",
    "class VideoStream:\n",
    "    def __init__(self, src):\n",
    "        self.stream = cv.VideoCapture(src)\n",
    "        self.stopped = False\n",
    "        self.frame = None\n",
    "\n",
    "    def start(self):\n",
    "        Thread(target=self.update, args=(), daemon=True).start()\n",
    "        return self\n",
    "\n",
    "    def update(self):\n",
    "        while not self.stopped:\n",
    "            if self.stream.isOpened():\n",
    "                ret, frame = self.stream.read()\n",
    "                if ret:\n",
    "                    self.frame = cv.resize(frame, (WIDTH, HEIGHT))\n",
    "\n",
    "    def read(self):\n",
    "        return self.frame\n",
    "\n",
    "    def stop(self):\n",
    "        self.stopped = True\n",
    "        self.stream.release()\n",
    "\n",
    "# === Initialize Streams ===\n",
    "vs1 = VideoStream('http://192.168.0.177:4747/video').start()  # Back view\n",
    "vs2 = VideoStream('http://192.168.0.114:4747/video').start()  # Front view\n",
    "\n",
    "# Initialize white canvases\n",
    "canvas1 = np.full((HEIGHT, WIDTH, 3), 255, dtype=np.uint8)\n",
    "canvas2 = np.full((HEIGHT, WIDTH, 3), 255, dtype=np.uint8)\n",
    "last_point1, last_point2 = None, None\n",
    "\n",
    "# === MediaPipe Setup ===\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(\n",
    "    static_image_mode=False,\n",
    "    max_num_hands=1,\n",
    "    min_detection_confidence=0.7,\n",
    "    min_tracking_confidence=0.6\n",
    ")\n",
    "\n",
    "def detect_fingertip(frame):\n",
    "    if frame is None:\n",
    "        return None\n",
    "    \n",
    "    frame_rgb = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "    results = hands.process(frame_rgb)\n",
    "    \n",
    "    if results.multi_hand_landmarks:\n",
    "        hand_landmarks = results.multi_hand_landmarks[0]\n",
    "        index_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "        x = int(index_tip.x * WIDTH)\n",
    "        y = int(index_tip.y * HEIGHT)\n",
    "        cv.circle(frame, (x, y), 10, (0, 255, 0), -1)\n",
    "        return (x, y)\n",
    "    return None\n",
    "\n",
    "def update_canvas(canvas, point, last_point):\n",
    "    if point:\n",
    "        cv.circle(canvas, point, LINE_THICKNESS//2, DRAW_COLOR, -1)\n",
    "        if last_point and (point != last_point):\n",
    "            cv.line(canvas, last_point, point, DRAW_COLOR, LINE_THICKNESS)\n",
    "\n",
    "def compare_drawings(img1, img2):\n",
    "    # Convert to grayscale and threshold\n",
    "    gray1 = cv.cvtColor(img1, cv.COLOR_BGR2GRAY)\n",
    "    gray2 = cv.cvtColor(img2, cv.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply threshold to get binary images\n",
    "    _, thresh1 = cv.threshold(gray1, 200, 255, cv.THRESH_BINARY_INV)\n",
    "    _, thresh2 = cv.threshold(gray2, 200, 255, cv.THRESH_BINARY_INV)\n",
    "    \n",
    "    # Find contours for each drawing\n",
    "    contours1, _ = cv.findContours(thresh1, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "    contours2, _ = cv.findContours(thresh2, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Create blank masks\n",
    "    mask1 = np.zeros_like(thresh1)\n",
    "    mask2 = np.zeros_like(thresh2)\n",
    "    \n",
    "    # Draw contours on masks\n",
    "    cv.drawContours(mask1, contours1, -1, 255, thickness=cv.FILLED)\n",
    "    cv.drawContours(mask2, contours2, -1, 255, thickness=cv.FILLED)\n",
    "    \n",
    "    # Calculate intersection and union\n",
    "    intersection = cv.bitwise_and(mask1, mask2)\n",
    "    union = cv.bitwise_or(mask1, mask2)\n",
    "    \n",
    "    # Calculate similarity\n",
    "    intersection_area = cv.countNonZero(intersection)\n",
    "    union_area = cv.countNonZero(union)\n",
    "    \n",
    "    if union_area == 0:\n",
    "        return 0.0, np.zeros_like(img1)\n",
    "    \n",
    "    similarity = intersection_area / union_area\n",
    "    \n",
    "    # Create difference visualization\n",
    "    diff = cv.bitwise_xor(mask1, mask2)\n",
    "    diff_visual = cv.cvtColor(diff, cv.COLOR_GRAY2BGR)\n",
    "    \n",
    "    return similarity, diff_visual\n",
    "\n",
    "# Main loop\n",
    "while True:\n",
    "    frame1 = vs1.read()\n",
    "    frame2 = vs2.read()\n",
    "\n",
    "    if frame1 is None or frame2 is None:\n",
    "        continue\n",
    "\n",
    "    point1 = detect_fingertip(frame1)\n",
    "    point2 = detect_fingertip(frame2)\n",
    "\n",
    "    if point1:\n",
    "        update_canvas(canvas1, point1, last_point1)\n",
    "        last_point1 = point1\n",
    "    if point2:\n",
    "        update_canvas(canvas2, point2, last_point2)\n",
    "        last_point2 = point2\n",
    "\n",
    "    # Compare drawings\n",
    "    score, diff_vis = compare_drawings(canvas1, canvas2)\n",
    "    \n",
    "    # Display views\n",
    "    cv.imshow(\"Back Camera\", frame1)\n",
    "    cv.imshow(\"Front Camera\", frame2)\n",
    "    cv.imshow(\"Back Drawing\", canvas1)\n",
    "    cv.imshow(\"Front Drawing\", canvas2)\n",
    "    \n",
    "    # Show difference and score\n",
    "    cv.putText(diff_vis, f\"Similarity: {score:.2f}\", (10, 30),\n",
    "               cv.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "    cv.imshow(\"Difference\", diff_vis)\n",
    "\n",
    "    key = cv.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('r'):\n",
    "        canvas1.fill(255)\n",
    "        canvas2.fill(255)\n",
    "        last_point1 = last_point2 = None\n",
    "\n",
    "# Cleanup\n",
    "vs1.stop()\n",
    "vs2.stop()\n",
    "hands.close()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf91f250",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from mediapipe.tasks import python\n",
    "from threading import Thread\n",
    "from mediapipe.tasks.python import vision\n",
    "import time\n",
    "\n",
    "# === MediaPipe Hand Detection Setup ===\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(\n",
    "    static_image_mode=False,\n",
    "    max_num_hands=1,\n",
    "    min_detection_confidence=0.7,\n",
    "    min_tracking_confidence=0.6\n",
    ")\n",
    "\n",
    "# === VideoStream Class for Better Performance ===\n",
    "\n",
    "class VideoStream:\n",
    "    def __init__(self, url):\n",
    "        self.stream = cv.VideoCapture(url)\n",
    "        self.stopped = False\n",
    "        self.frame = None\n",
    "\n",
    "    def start(self):\n",
    "        Thread(target=self.update, args=(), daemon=True).start()\n",
    "        return self\n",
    "\n",
    "    def update(self):\n",
    "        while not self.stopped:\n",
    "            if self.stream.isOpened():\n",
    "                ret, frame = self.stream.read()\n",
    "                if ret:\n",
    "                    self.frame = frame\n",
    "\n",
    "    def read(self):\n",
    "        return self.frame\n",
    "\n",
    "    def stop(self):\n",
    "        self.stopped = True\n",
    "        self.stream.release()\n",
    "\n",
    "# === Initialize Video Streams ===\n",
    "vs1 = VideoStream('http://192.168.0.177:4747/video').start()  # Back view\n",
    "vs2 = VideoStream('http://192.168.0.114:4747/video').start()  # Front view\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066a3aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from mediapipe.tasks import python\n",
    "from threading import Thread\n",
    "from mediapipe.tasks.python import vision\n",
    "import time\n",
    "\n",
    "# === MediaPipe Hand Detection Setup ===\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(\n",
    "    static_image_mode=False,\n",
    "    max_num_hands=1,\n",
    "    min_detection_confidence=0.7,\n",
    "    min_tracking_confidence=0.6\n",
    ")\n",
    "\n",
    "# === VideoStream Class for Better Performance ===\n",
    "\n",
    "class VideoStream:\n",
    "    def __init__(self, url):\n",
    "        self.stream = cv.VideoCapture(url)\n",
    "        self.stopped = False\n",
    "        self.frame = None\n",
    "\n",
    "    def start(self):\n",
    "        Thread(target=self.update, args=(), daemon=True).start()\n",
    "        return self\n",
    "\n",
    "    def update(self):\n",
    "        while not self.stopped:\n",
    "            if self.stream.isOpened():\n",
    "                ret, frame = self.stream.read()\n",
    "                if ret:\n",
    "                    self.frame = frame\n",
    "\n",
    "    def read(self):\n",
    "        return self.frame\n",
    "\n",
    "    def stop(self):\n",
    "        self.stopped = True\n",
    "        self.stream.release()\n",
    "\n",
    "# === Initialize Video Streams ===\n",
    "vs1 = VideoStream('http://192.168.0.177:4747/video').start()  # Back view\n",
    "vs2 = VideoStream('http://192.168.0.114:4747/video').start()  # Front view\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def classify_pose(hand_landmarks):\n",
    "    # Get key landmarks (using correct MediaPipe indices)\n",
    "    thumb_tip = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP]\n",
    "    index_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "    index_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_MCP]  # Middle joint\n",
    "    middle_tip = hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_TIP]\n",
    "    middle_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_MCP]\n",
    "    \n",
    "    # Finger states (True = extended)\n",
    "    index_extended = index_tip.y < index_mcp.y\n",
    "    middle_extended = middle_tip.y < middle_mcp.y\n",
    "    thumb_extended = thumb_tip.x < index_mcp.x  # Works for right hand\n",
    "    \n",
    "    # Pose classification\n",
    "    if index_extended and middle_extended and not thumb_extended:\n",
    "        return \"VICTORY\"  # âœŒï¸\n",
    "    elif not index_extended and not middle_extended:\n",
    "        return \"FIST\"  # âœŠ\n",
    "    elif index_extended and not middle_extended and thumb_extended:\n",
    "        return \"THUMBS_UP\"  # ðŸ‘\n",
    "    else:\n",
    "        return \"OPEN\"  # âœ‹\n",
    "    \n",
    "\n",
    "# Create named windows first (for consistent sizing)\n",
    "cv.namedWindow(\"Player 1 View\", cv.WINDOW_NORMAL)\n",
    "cv.namedWindow(\"Player 2 View\", cv.WINDOW_NORMAL)\n",
    "cv.namedWindow(\"Mirror Challenge Game\", cv.WINDOW_NORMAL)\n",
    "\n",
    "while True:\n",
    "    frame1 = vs1.read()  # Player 1\n",
    "    frame2 = vs2.read()  # Player 2\n",
    "    \n",
    "    # Process frames and get poses (your existing code)\n",
    "    p1_pose = None\n",
    "    p2_pose = None\n",
    "    \n",
    "    # Process Player 1\n",
    "    if frame1 is not None:\n",
    "        results1 = hands.process(cv.cvtColor(frame1, cv.COLOR_BGR2RGB))\n",
    "        if results1.multi_hand_landmarks:\n",
    "            p1_pose = classify_pose(results1.multi_hand_landmarks[0])\n",
    "            # Draw landmarks on frame\n",
    "            mp_drawing.draw_landmarks(\n",
    "                frame1, results1.multi_hand_landmarks[0], \n",
    "                mp_hands.HAND_CONNECTIONS)\n",
    "    \n",
    "    # Process Player 2\n",
    "    if frame2 is not None:\n",
    "        results2 = hands.process(cv.cvtColor(frame2, cv.COLOR_BGR2RGB))\n",
    "        if results2.multi_hand_landmarks:\n",
    "            p2_pose = classify_pose(results2.multi_hand_landmarks[0])\n",
    "            mp_drawing.draw_landmarks(\n",
    "                frame2, results2.multi_hand_landmarks[0], \n",
    "                mp_hands.HAND_CONNECTIONS)\n",
    "    \n",
    "    # Create game output display\n",
    "    output = np.zeros((480, 640, 3), dtype=np.uint8)\n",
    "    \n",
    "    # Add game info to output\n",
    "    cv.putText(output, f\"Player 1: {p1_pose or 'No pose'}\", (50, 50), \n",
    "               cv.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 0), 2)\n",
    "    cv.putText(output, f\"Player 2: {p2_pose or 'No pose'}\", (50, 100), \n",
    "               cv.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 0), 2)\n",
    "    cv.putText(output, \"Mirror the pose with 1s delay!\", (50, 150), \n",
    "               cv.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 1)\n",
    "    \n",
    "    # Display all windows\n",
    "    if frame1 is not None:\n",
    "        cv.imshow(\"Player 1 View\", frame1)\n",
    "    if frame2 is not None:\n",
    "        cv.imshow(\"Player 2 View\", frame2)\n",
    "    cv.imshow(\"Mirror Challenge Game\", output)\n",
    "    \n",
    "    # Exit on 'q' key\n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "vs1.stop()\n",
    "vs2.stop()\n",
    "hands.close()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af9f1f28",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 35\u001b[0m\n\u001b[0;32m     33\u001b[0m     last_match_time \u001b[38;5;241m=\u001b[39m current_time\n\u001b[0;32m     34\u001b[0m pose_history\u001b[38;5;241m.\u001b[39mremove((timestamp, historic_pose))\n\u001b[1;32m---> 35\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create named windows first (for consistent sizing)\n",
    "cv.namedWindow(\"Player 1 View\", cv.WINDOW_NORMAL)\n",
    "cv.namedWindow(\"Player 2 View\", cv.WINDOW_NORMAL)\n",
    "cv.namedWindow(\"Mirror Challenge Game\", cv.WINDOW_NORMAL)\n",
    "\n",
    "while True:\n",
    "    frame1 = vs1.read()  # Player 1\n",
    "    frame2 = vs2.read()  # Player 2\n",
    "    \n",
    "    # Process frames and get poses (your existing code)\n",
    "    p1_pose = None\n",
    "    p2_pose = None\n",
    "    \n",
    "    # Process Player 1\n",
    "    if frame1 is not None:\n",
    "        results1 = hands.process(cv.cvtColor(frame1, cv.COLOR_BGR2RGB))\n",
    "        if results1.multi_hand_landmarks:\n",
    "            p1_pose = classify_pose(results1.multi_hand_landmarks[0])\n",
    "            # Draw landmarks on frame\n",
    "            mp_drawing.draw_landmarks(\n",
    "                frame1, results1.multi_hand_landmarks[0], \n",
    "                mp_hands.HAND_CONNECTIONS)\n",
    "    \n",
    "    # Process Player 2\n",
    "    if frame2 is not None:\n",
    "        results2 = hands.process(cv.cvtColor(frame2, cv.COLOR_BGR2RGB))\n",
    "        if results2.multi_hand_landmarks:\n",
    "            p2_pose = classify_pose(results2.multi_hand_landmarks[0])\n",
    "            mp_drawing.draw_landmarks(\n",
    "                frame2, results2.multi_hand_landmarks[0], \n",
    "                mp_hands.HAND_CONNECTIONS)\n",
    "    \n",
    "    # Create game output display\n",
    "    output = np.zeros((480, 640, 3), dtype=np.uint8)\n",
    "    \n",
    "    # Add game info to output\n",
    "    cv.putText(output, f\"Player 1: {p1_pose or 'No pose'}\", (50, 50), \n",
    "               cv.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 0), 2)\n",
    "    cv.putText(output, f\"Player 2: {p2_pose or 'No pose'}\", (50, 100), \n",
    "               cv.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 0), 2)\n",
    "    cv.putText(output, \"Mirror the pose with 1s delay!\", (50, 150), \n",
    "               cv.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 1)\n",
    "    \n",
    "    # Display all windows\n",
    "    if frame1 is not None:\n",
    "        cv.imshow(\"Player 1 View\", frame1)\n",
    "    if frame2 is not None:\n",
    "        cv.imshow(\"Player 2 View\", frame2)\n",
    "    cv.imshow(\"Mirror Challenge Game\", output)\n",
    "    \n",
    "    # Exit on 'q' key\n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "vs1.stop()\n",
    "vs2.stop()\n",
    "hands.close()\n",
    "cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
